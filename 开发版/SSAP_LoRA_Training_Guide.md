# SSAPæ¡†æ¶LoRAè®­ç»ƒæŒ‡å—

## ğŸ¯ è®­ç»ƒç›®æ ‡ä¸æœŸæœ›

### æ ¸å¿ƒå­¦ä¹ ç›®æ ‡
1. **ç»“æ„åŒ–æ€ç»´**: æŒæ¡SSAPä¸ƒå±‚æ¶æ„çš„è®¾è®¡æ¨¡å¼
2. **ç»Ÿä¸€è°ƒç”¨**: å­¦ä¼š`[Knowledge.åç§°]`ã€`[Skills.åç§°]`ç­‰ç»Ÿä¸€è°ƒç”¨æ ¼å¼
3. **ä¼ªä»£ç é€»è¾‘**: ç†è§£`FUNCTION...BEGIN...END`çš„å·¥ä½œæµç¼–æ’
4. **æ ¼å¼æ§åˆ¶**: æŒæ¡ä¸‰å¤§æ ¼å¼æ¨¡å—çš„è¾“å‡ºæ§åˆ¶
5. **æ™ºèƒ½ååŒ**: å­¦ä¼šæ€ç»´é“¾å’Œä¸Šä¸‹æ–‡ç®¡ç†çš„ååŒæœºåˆ¶

### æœŸæœ›è®­ç»ƒæ•ˆæœ
- **æ¶æ„ä¸€è‡´æ€§**: ç”Ÿæˆçš„æ™ºèƒ½ä½“éƒ½éµå¾ªSSAPä¸ƒå±‚æ¶æ„
- **è°ƒç”¨è§„èŒƒæ€§**: ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å—è°ƒç”¨æ ¼å¼
- **é€»è¾‘æ¸…æ™°æ€§**: å·¥ä½œæµé€»è¾‘ç»“æ„åŒ–ã€å¯é¢„æµ‹
- **è¾“å‡ºä¸“ä¸šæ€§**: æ ¼å¼åŒ–è¾“å‡ºç¬¦åˆä¸“ä¸šæ ‡å‡†
- **æ€ç»´æ·±åº¦**: å¤æ‚é—®é¢˜å±•ç°æ·±åº¦æ€ç»´èƒ½åŠ›

---

## ğŸ“Š è®­ç»ƒå‚æ•°é…ç½®

### åŸºç¡€LoRAå‚æ•°

#### æ¨èé…ç½®ï¼ˆåŸºäºæ•°æ®é›†ç‰¹å¾åˆ†æï¼‰
```yaml
# LoRAæ ¸å¿ƒå‚æ•°
rank: 32  # è¾ƒé«˜Ranké€‚åº”SSAPæ¡†æ¶çš„å¤æ‚ç»“æ„
alpha: 64  # Alpha=2*Rankï¼Œå¹³è¡¡å­¦ä¹ å¼ºåº¦
dropout: 0.05  # ä½dropoutä¿æŒç»“æ„åŒ–å­¦ä¹ 

# å­¦ä¹ ç‡é…ç½®
learning_rate: 2e-4  # é€‚ä¸­å­¦ä¹ ç‡ï¼Œé¿å…ç»“æ„æ€§çŸ¥è¯†æŸå¤±
warmup_steps: 100  # é¢„çƒ­æ­¥éª¤ï¼Œç¨³å®šè®­ç»ƒå¼€å§‹
lr_scheduler: "cosine"  # ä½™å¼¦é€€ç«ï¼Œé€‚åˆç»“æ„åŒ–è®­ç»ƒ

# æ‰¹æ¬¡é…ç½®
per_device_train_batch_size: 4
gradient_accumulation_steps: 8  # æœ‰æ•ˆæ‰¹æ¬¡å¤§å°=32
max_length: 2048  # æ”¯æŒå®Œæ•´SSAPæ¶æ„æ–‡æœ¬

# è®­ç»ƒè½®æ•°
num_train_epochs: 3
save_steps: 500
evaluation_steps: 250
```

#### é«˜çº§ä¼˜åŒ–é…ç½®
```yaml
# ä¼˜åŒ–å™¨è®¾ç½®
optimizer: "adamw_8bit"  # å†…å­˜ä¼˜åŒ–
weight_decay: 0.01
adam_beta1: 0.9
adam_beta2: 0.999

# æ··åˆç²¾åº¦è®­ç»ƒ
fp16: true  # åŠ é€Ÿè®­ç»ƒï¼ŒèŠ‚çœæ˜¾å­˜
dataloader_pin_memory: true

# æ¨¡å‹ä¿å­˜ç­–ç•¥
save_total_limit: 3  # ä¿ç•™æœ€ä½³3ä¸ªæ£€æŸ¥ç‚¹
load_best_model_at_end: true
metric_for_best_model: "eval_loss"
greater_is_better: false
```

### åˆ†å±‚è®­ç»ƒç­–ç•¥

#### é˜¶æ®µä¸€ï¼šåŸºç¡€æ¶æ„å­¦ä¹ ï¼ˆEpoch 1ï¼‰
```yaml
# ä¸“æ³¨åŸºç¡€æ¶æ„å’Œè°ƒç”¨æ ¼å¼å­¦ä¹ 
learning_rate: 3e-4  # ç›¸å¯¹è¾ƒé«˜ï¼Œå¿«é€Ÿå­¦ä¹ ç»“æ„
target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]  # ä¸“æ³¨æ³¨æ„åŠ›æœºåˆ¶
```

#### é˜¶æ®µäºŒï¼šé€»è¾‘ç¼–æ’ä¼˜åŒ–ï¼ˆEpoch 2ï¼‰
```yaml
# å¼ºåŒ–å·¥ä½œæµé€»è¾‘å’Œæ ¼å¼æ§åˆ¶
learning_rate: 2e-4  # é€‚ä¸­å­¦ä¹ ç‡ï¼Œå¹³è¡¡å­¦ä¹ 
target_modules: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
```

#### é˜¶æ®µä¸‰ï¼šæ™ºèƒ½ååŒç²¾è°ƒï¼ˆEpoch 3ï¼‰
```yaml
# æœ€ç»ˆä¼˜åŒ–æ™ºèƒ½ååŒèƒ½åŠ›
learning_rate: 1e-4  # è¾ƒä½å­¦ä¹ ç‡ï¼Œç²¾ç»†è°ƒä¼˜
target_modules: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj", "embed_tokens"]
```

---

## ğŸ”§ æ•°æ®é¢„å¤„ç†é…ç½®

### æ•°æ®æ ¼å¼æ ‡å‡†åŒ–

#### è®­ç»ƒæ–‡æœ¬æ ¼å¼
```json
{
  "instruction": "åŸºäºSSAPæ¡†æ¶è®¾è®¡ä¸€ä¸ª[ä¸“ä¸šé¢†åŸŸ]æ™ºèƒ½ä½“",
  "input": "[å…·ä½“éœ€æ±‚æè¿°]", 
  "output": "[å®Œæ•´çš„SSAPæ¶æ„æ™ºèƒ½ä½“ä»£ç ]",
  "labels": {
    "english": "SSAP_framework, [domain], [key_features]",
    "chinese": "SSAPæ¡†æ¶, [é¢†åŸŸ], [å…³é”®ç‰¹å¾]"
  }
}
```

#### æ•°æ®å¢å¼ºç­–ç•¥
```yaml
# åŒä¹‰è¯æ›¿æ¢ï¼ˆä¿æŒSSAPç»“æ„ä¸å˜ï¼‰
synonym_replacement: 0.1
# å¥å¼é‡æ’ï¼ˆä¿æŒé€»è¾‘ç»“æ„ï¼‰
sentence_shuffle: 0.05
# ä¸“ä¸šæœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥
terminology_check: true
```

### è´¨é‡è¿‡æ»¤æœºåˆ¶

#### è‡ªåŠ¨è´¨é‡æ£€æŸ¥
```python
def quality_check(sample):
    checks = {
        "has_ssap_structure": check_ssap_layers(sample),
        "has_unified_calls": check_call_format(sample),
        "has_pseudocode": check_workflow_structure(sample),
        "has_format_modules": check_format_modules(sample),
        "terminology_accuracy": check_professional_terms(sample)
    }
    return all(checks.values())
```

#### æ‰‹åŠ¨å®¡æ ¸æ ‡å‡†
- âœ… SSAPä¸ƒå±‚æ¶æ„å®Œæ•´æ€§
- âœ… ç»Ÿä¸€è°ƒç”¨æ ¼å¼è§„èŒƒæ€§  
- âœ… ä¸“ä¸šæœ¯è¯­å‡†ç¡®æ€§
- âœ… é€»è¾‘ç»“æ„æ¸…æ™°æ€§
- âœ… æ ‡æ³¨å†…å®¹ä¸€è‡´æ€§

---

## ğŸš€ è®­ç»ƒå®æ–½æ­¥éª¤

### Step 1: ç¯å¢ƒå‡†å¤‡
```bash
# å®‰è£…è®­ç»ƒç¯å¢ƒ
pip install transformers==4.35.0
pip install peft==0.7.0
pip install bitsandbytes==0.41.0
pip install accelerate==0.24.0

# éªŒè¯GPUç¯å¢ƒ
python -c "import torch; print(torch.cuda.is_available())"
```

### Step 2: æ•°æ®é›†åŠ è½½
```python
from datasets import Dataset, DatasetDict
import json

# åŠ è½½SSAPæ•°æ®é›†
def load_ssap_dataset():
    with open('SSAP_LoRA_Dataset.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # æŒ‰ç±»åˆ«åˆ†å‰²
    train_data = []
    eval_data = []
    
    for category, samples in data.items():
        # 80%è®­ç»ƒï¼Œ20%éªŒè¯
        split_idx = int(len(samples) * 0.8)
        train_data.extend(samples[:split_idx])
        eval_data.extend(samples[split_idx:])
    
    return DatasetDict({
        'train': Dataset.from_list(train_data),
        'eval': Dataset.from_list(eval_data)
    })
```

### Step 3: æ¨¡å‹é…ç½®
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import LoraConfig, get_peft_model

# åŸºç¡€æ¨¡å‹åŠ è½½
model_name = "Qwen/Qwen2.5-7B-Instruct"  # æˆ–å…¶ä»–åˆé€‚çš„åŸºç¡€æ¨¡å‹
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

# LoRAé…ç½®
lora_config = LoraConfig(
    r=32,
    lora_alpha=64,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

model = get_peft_model(model, lora_config)
```

### Step 4: è®­ç»ƒæ‰§è¡Œ
```python
from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="./ssap_lora_checkpoints",
    per_device_train_batch_size=4,
    gradient_accumulation_steps=8,
    learning_rate=2e-4,
    num_train_epochs=3,
    warmup_steps=100,
    logging_steps=50,
    save_steps=500,
    evaluation_strategy="steps",
    eval_steps=250,
    fp16=True,
    remove_unused_columns=False,
    dataloader_pin_memory=True,
    save_total_limit=3,
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    report_to="wandb"  # å¯é€‰ï¼šä½¿ç”¨wandbç›‘æ§
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset['train'],
    eval_dataset=dataset['eval'],
    tokenizer=tokenizer,
)

# å¼€å§‹è®­ç»ƒ
trainer.train()
```

---

## ğŸ“ˆ è®­ç»ƒç›‘æ§ä¸è¯„ä¼°

### å…³é”®æŒ‡æ ‡ç›‘æ§

#### è®­ç»ƒè¿‡ç¨‹æŒ‡æ ‡
```yaml
loss_metrics:
  - train_loss: "< 1.5"  # ç›®æ ‡è®­ç»ƒæŸå¤±
  - eval_loss: "< 1.8"   # ç›®æ ‡éªŒè¯æŸå¤±
  - perplexity: "< 6.0"  # å›°æƒ‘åº¦æŒ‡æ ‡

convergence_metrics:
  - learning_rate_decay: "smooth"
  - gradient_norm: "< 1.0"
  - weight_updates: "stable"
```

#### SSAPç‰¹å¼‚æ€§è¯„ä¼°
```python
def evaluate_ssap_quality(model, tokenizer, test_samples):
    """è¯„ä¼°SSAPæ¡†æ¶å­¦ä¹ è´¨é‡"""
    
    scores = {
        'architecture_completeness': 0,  # æ¶æ„å®Œæ•´æ€§
        'call_format_consistency': 0,    # è°ƒç”¨æ ¼å¼ä¸€è‡´æ€§
        'workflow_logic_clarity': 0,     # å·¥ä½œæµé€»è¾‘æ¸…æ™°æ€§
        'format_module_usage': 0,        # æ ¼å¼æ¨¡å—ä½¿ç”¨æ­£ç¡®æ€§
        'professional_terminology': 0    # ä¸“ä¸šæœ¯è¯­å‡†ç¡®æ€§
    }
    
    for sample in test_samples:
        output = generate_response(model, tokenizer, sample['instruction'])
        
        # è¯„ä¼°å„é¡¹æŒ‡æ ‡
        scores['architecture_completeness'] += check_seven_layers(output)
        scores['call_format_consistency'] += check_unified_calls(output)
        scores['workflow_logic_clarity'] += check_pseudocode_logic(output)
        scores['format_module_usage'] += check_format_modules(output)
        scores['professional_terminology'] += check_terminology(output)
    
    # è®¡ç®—å¹³å‡åˆ†
    for key in scores:
        scores[key] = scores[key] / len(test_samples) * 100
    
    return scores
```

### è´¨é‡éªŒè¯æµ‹è¯•

#### è‡ªåŠ¨åŒ–æµ‹è¯•ç”¨ä¾‹
```python
test_cases = [
    {
        "name": "æ•°æ®ç§‘å­¦ä¸“å®¶ç”Ÿæˆ",
        "prompt": "è®¾è®¡ä¸€ä¸ªä¸“ç²¾æœºå™¨å­¦ä¹ çš„æ•°æ®ç§‘å­¦ä¸“å®¶æ™ºèƒ½ä½“",
        "expected_features": [
            "identityå±‚å®šä¹‰",
            "ä¸“ä¸šçŸ¥è¯†ä½“ç³»",
            "æ ¸å¿ƒæŠ€èƒ½æ¨¡å—",
            "[Knowledge.ç»Ÿè®¡å­¦ç†è®º]è°ƒç”¨",
            "FUNCTION...BEGIN...ENDç»“æ„"
        ]
    },
    {
        "name": "å·¥ä½œæµç¼–æ’æµ‹è¯•", 
        "prompt": "åˆ›å»ºä¸€ä¸ªåŒ…å«æ¡ä»¶åˆ†æ”¯çš„æ•°æ®åˆ†æå·¥ä½œæµ",
        "expected_features": [
            "IF...THEN...ELSEç»“æ„",
            "STOP_AND_WAITæœºåˆ¶",
            "[Skills.æ‰¹é‡è°ƒç”¨]æ ¼å¼",
            "[Format.æ ¼å¼æ¨¡å—]è°ƒç”¨"
        ]
    },
    {
        "name": "æ™ºèƒ½ååŒæµ‹è¯•",
        "prompt": "è®¾è®¡ä¸€ä¸ªéœ€è¦æ€ç»´é“¾ååŒçš„å¤æ‚é—®é¢˜è§£å†³æµç¨‹",
        "expected_features": [
            "[Thinking.æ€ç»´ç±»å‹]è°ƒç”¨",
            "[Context.ä¸Šä¸‹æ–‡ç®¡ç†]ä½¿ç”¨",
            "æ™ºèƒ½è°ƒåº¦é€»è¾‘",
            "ååŒæ¨¡å¼åˆ‡æ¢"
        ]
    }
]
```

#### äººå·¥è¯„ä¼°æ ‡å‡†
| è¯„ä¼°ç»´åº¦ | æƒé‡ | è¯„åˆ†æ ‡å‡† | ç›®æ ‡åˆ†æ•° |
|----------|------|----------|----------|
| æ¶æ„å®Œæ•´æ€§ | 25% | æ˜¯å¦åŒ…å«å®Œæ•´ä¸ƒå±‚æ¶æ„ | â‰¥90% |
| è°ƒç”¨è§„èŒƒæ€§ | 20% | ç»Ÿä¸€è°ƒç”¨æ ¼å¼ä½¿ç”¨æ­£ç¡®æ€§ | â‰¥95% |
| é€»è¾‘æ¸…æ™°æ€§ | 20% | å·¥ä½œæµé€»è¾‘ç»“æ„æ¸…æ™°åº¦ | â‰¥85% |
| ä¸“ä¸šå‡†ç¡®æ€§ | 20% | ä¸“ä¸šæœ¯è¯­å’Œæ–¹æ³•æ­£ç¡®æ€§ | â‰¥90% |
| åˆ›æ–°ååŒæ€§ | 15% | æ™ºèƒ½ååŒæœºåˆ¶ä½“ç°ç¨‹åº¦ | â‰¥80% |

---

## âš ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### è®­ç»ƒé—®é¢˜æ’æŸ¥

#### é—®é¢˜1ï¼šæŸå¤±ä¸æ”¶æ•›
**ç—‡çŠ¶**: è®­ç»ƒæŸå¤±æŒç»­éœ‡è¡ï¼Œä¸æ”¶æ•›
**åŸå› åˆ†æ**: 
- å­¦ä¹ ç‡è¿‡é«˜ï¼Œç ´åäº†ç»“æ„åŒ–çŸ¥è¯†
- æ•°æ®è´¨é‡ä¸ä¸€è‡´ï¼Œå­˜åœ¨å†²çªæ ·æœ¬

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# é™ä½å­¦ä¹ ç‡
learning_rate: 1e-4  # ä»2e-4é™ä½åˆ°1e-4

# å¢åŠ warmup
warmup_ratio: 0.1  # å¢åŠ é¢„çƒ­æ¯”ä¾‹

# æ•°æ®è´¨é‡æ£€æŸ¥
enable_data_validation: true
remove_conflicting_samples: true
```

#### é—®é¢˜2ï¼šè¿‡æ‹Ÿåˆä¸¥é‡
**ç—‡çŠ¶**: è®­ç»ƒæŸå¤±å¾ˆä½ä½†éªŒè¯æŸå¤±å¾ˆé«˜
**åŸå› åˆ†æ**: 
- æ•°æ®é›†è§„æ¨¡ç›¸å¯¹æ¨¡å‹å¤æ‚åº¦è¾ƒå°
- å­¦ä¹ ç‡è¿‡é«˜å¯¼è‡´è¿‡åº¦è®°å¿†

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# å¢åŠ æ­£åˆ™åŒ–
lora_dropout: 0.1  # ä»0.05å¢åŠ åˆ°0.1
weight_decay: 0.02  # å¢åŠ æƒé‡è¡°å‡

# æ—©åœæœºåˆ¶
early_stopping_patience: 3
early_stopping_threshold: 0.01

# æ•°æ®å¢å¼º
enable_data_augmentation: true
augmentation_ratio: 0.2
```

#### é—®é¢˜3ï¼šSSAPç‰¹å¾å­¦ä¹ ä¸å……åˆ†
**ç—‡çŠ¶**: ç”Ÿæˆçš„å†…å®¹ä¸ç¬¦åˆSSAPæ¡†æ¶è§„èŒƒ
**åŸå› åˆ†æ**: 
- åŸºç¡€æ¨¡å‹å¯¹SSAPæ¡†æ¶ç†è§£ä¸è¶³
- è®­ç»ƒæ•°æ®ä¸­SSAPç‰¹å¾ä¸å¤Ÿçªå‡º

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# å¢å¼ºSSAPç‰¹å¾æƒé‡
ssap_feature_weight: 2.0
curriculum_learning: true

# åˆ†é˜¶æ®µè®­ç»ƒ
stage1_focus: "architecture_learning"
stage2_focus: "format_learning" 
stage3_focus: "collaboration_learning"

# å¢åŠ SSAPç›¸å…³æ•°æ®
ssap_core_samples_ratio: 0.4
```

### ä¼˜åŒ–å»ºè®®

#### è®­ç»ƒæ•ˆç‡ä¼˜åŒ–
```python
# æ¢¯åº¦æ£€æŸ¥ç‚¹
gradient_checkpointing: true

# å†…å­˜ä¼˜åŒ–
max_memory_usage: "80%"
use_8bit_optimizer: true

# å¹¶è¡Œè®­ç»ƒ
dataloader_num_workers: 4
prefetch_factor: 2
```

#### è´¨é‡æå‡ç­–ç•¥
```python
# è´¨é‡å¯¼å‘è®­ç»ƒ
quality_weighted_loss: true
quality_threshold: 0.85

# äººå·¥åé¦ˆé›†æˆ
enable_human_feedback: true
feedback_frequency: 100  # æ¯100æ­¥æ”¶é›†ä¸€æ¬¡åé¦ˆ
```

---

## ğŸ“‹ è®­ç»ƒæ¸…å•

### è®­ç»ƒå‰æ£€æŸ¥
- [ ] æ•°æ®é›†è´¨é‡éªŒè¯å®Œæˆ
- [ ] è®­ç»ƒç¯å¢ƒé…ç½®æ­£ç¡®
- [ ] GPUå†…å­˜å……è¶³ï¼ˆå»ºè®®â‰¥24GBï¼‰
- [ ] åŸºç¡€æ¨¡å‹ä¸‹è½½å®Œæˆ
- [ ] ç›‘æ§å·¥å…·é…ç½®å°±ç»ª

### è®­ç»ƒä¸­ç›‘æ§
- [ ] æŸå¤±æ›²çº¿æ­£å¸¸ä¸‹é™
- [ ] éªŒè¯æŒ‡æ ‡ç¨³å®šæå‡
- [ ] GPUåˆ©ç”¨ç‡ä¿æŒé«˜æ•ˆ
- [ ] å†…å­˜ä½¿ç”¨åœ¨å®‰å…¨èŒƒå›´
- [ ] å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹

### è®­ç»ƒåéªŒè¯
- [ ] SSAPç‰¹å¼‚æ€§è¯„ä¼°é€šè¿‡
- [ ] äººå·¥è´¨é‡è¯„ä¼°è¾¾æ ‡
- [ ] è‡ªåŠ¨åŒ–æµ‹è¯•å…¨éƒ¨é€šè¿‡
- [ ] æ¨¡å‹å¤§å°ç¬¦åˆé¢„æœŸ
- [ ] æ¨ç†é€Ÿåº¦æ»¡è¶³è¦æ±‚

---

## ğŸ¯ æœŸæœ›ç»“æœ

### è®­ç»ƒæˆåŠŸæ ‡å‡†
1. **é‡åŒ–æŒ‡æ ‡**:
   - è®­ç»ƒæŸå¤± < 1.5
   - éªŒè¯æŸå¤± < 1.8
   - SSAPæ¶æ„å®Œæ•´æ€§ â‰¥ 90%
   - è°ƒç”¨æ ¼å¼ä¸€è‡´æ€§ â‰¥ 95%

2. **è´¨é‡æ ‡å‡†**:
   - ç”Ÿæˆçš„æ™ºèƒ½ä½“éµå¾ªSSAPä¸ƒå±‚æ¶æ„
   - ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å—è°ƒç”¨æ ¼å¼
   - å·¥ä½œæµé€»è¾‘æ¸…æ™°å¯æ§
   - è¾“å‡ºæ ¼å¼ä¸“ä¸šè§„èŒƒ

3. **èƒ½åŠ›æ ‡å‡†**:
   - æ”¯æŒå¤šä¸“ä¸šé¢†åŸŸæ™ºèƒ½ä½“è®¾è®¡
   - å…·å¤‡æ™ºèƒ½ååŒå¤„ç†èƒ½åŠ›
   - èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ä¸“ä¸šå†…å®¹
   - ä¿æŒLess is Moreè®¾è®¡ç†å¿µ

é€šè¿‡è¿™ä¸ªè®­ç»ƒæ–¹æ¡ˆï¼Œæ‚¨å°†è·å¾—ä¸€ä¸ªæ·±åº¦æŒæ¡SSAPæ¡†æ¶çš„LoRAæ¨¡å‹ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡ã€ç»“æ„åŒ–çš„ä¸“ä¸šæ™ºèƒ½ä½“ï¼Œæ˜¾è‘—æå‡AIç³»ç»Ÿçš„è®¾è®¡æ•ˆç‡å’Œè¾“å‡ºè´¨é‡ã€‚ 