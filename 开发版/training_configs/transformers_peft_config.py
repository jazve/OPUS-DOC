#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SSAPæ¡†æ¶LoRAè®­ç»ƒé…ç½® - Transformers + PEFT
åŸºäºHuggingFace Transformerså’ŒPEFTåº“çš„è®­ç»ƒé…ç½®
"""

import torch
from dataclasses import dataclass
from typing import Optional
from transformers import TrainingArguments
from peft import LoraConfig, TaskType

@dataclass
class SSAPLoRAConfig:
    """SSAPæ¡†æ¶LoRAè®­ç»ƒé…ç½®"""
    
    # æ¨¡å‹é…ç½®
    model_name: str = "meta-llama/Llama-2-7b-hf"
    tokenizer_name: Optional[str] = None
    
    # æ•°æ®é…ç½®
    dataset_path: str = "SSAP_LoRA_Dataset.json"
    max_length: int = 2048
    train_split: float = 0.8
    
    # LoRAé…ç½®
    lora_r: int = 32
    lora_alpha: int = 64
    lora_dropout: float = 0.05
    lora_bias: str = "none"
    target_modules: list = None
    
    # è®­ç»ƒé…ç½®
    output_dir: str = "./ssap_lora_model"
    num_train_epochs: int = 3
    per_device_train_batch_size: int = 2
    per_device_eval_batch_size: int = 2
    gradient_accumulation_steps: int = 4
    learning_rate: float = 2e-4
    weight_decay: float = 0.01
    warmup_ratio: float = 0.03
    
    # ä¼˜åŒ–é…ç½®
    optim: str = "adamw_torch"
    lr_scheduler_type: str = "linear"
    fp16: bool = True
    bf16: bool = False
    
    # è¯„ä¼°å’Œä¿å­˜
    evaluation_strategy: str = "steps"
    eval_steps: int = 50
    save_strategy: str = "steps"
    save_steps: int = 100
    save_total_limit: int = 3
    load_best_model_at_end: bool = True
    metric_for_best_model: str = "eval_loss"
    
    # æ—¥å¿—é…ç½®
    logging_steps: int = 10
    report_to: str = "none"  # å¯è®¾ç½®ä¸º "wandb" æˆ– "tensorboard"
    
    # éšæœºç§å­
    seed: int = 3407
    
    def __post_init__(self):
        if self.tokenizer_name is None:
            self.tokenizer_name = self.model_name
            
        if self.target_modules is None:
            # Llamaæ¨¡å‹çš„é»˜è®¤ç›®æ ‡æ¨¡å—
            self.target_modules = [
                "q_proj", "k_proj", "v_proj", "o_proj",
                "gate_proj", "up_proj", "down_proj"
            ]

def get_lora_config(config: SSAPLoRAConfig) -> LoraConfig:
    """è·å–LoRAé…ç½®"""
    return LoraConfig(
        r=config.lora_r,
        lora_alpha=config.lora_alpha,
        target_modules=config.target_modules,
        lora_dropout=config.lora_dropout,
        bias=config.lora_bias,
        task_type=TaskType.CAUSAL_LM,
    )

def get_training_arguments(config: SSAPLoRAConfig) -> TrainingArguments:
    """è·å–è®­ç»ƒå‚æ•°"""
    return TrainingArguments(
        output_dir=config.output_dir,
        num_train_epochs=config.num_train_epochs,
        per_device_train_batch_size=config.per_device_train_batch_size,
        per_device_eval_batch_size=config.per_device_eval_batch_size,
        gradient_accumulation_steps=config.gradient_accumulation_steps,
        learning_rate=config.learning_rate,
        weight_decay=config.weight_decay,
        warmup_ratio=config.warmup_ratio,
        optim=config.optim,
        lr_scheduler_type=config.lr_scheduler_type,
        fp16=config.fp16,
        bf16=config.bf16,
        evaluation_strategy=config.evaluation_strategy,
        eval_steps=config.eval_steps,
        save_strategy=config.save_strategy,
        save_steps=config.save_steps,
        save_total_limit=config.save_total_limit,
        load_best_model_at_end=config.load_best_model_at_end,
        metric_for_best_model=config.metric_for_best_model,
        logging_steps=config.logging_steps,
        report_to=config.report_to,
        seed=config.seed,
        dataloader_pin_memory=False,
        remove_unused_columns=False,
    )

# SSAPæ¡†æ¶ç‰¹å®šé…ç½®
SSAP_QUALITY_METRICS = {
    "architecture_consistency": 0.90,  # æ¶æ„ä¸€è‡´æ€§ç›®æ ‡
    "calling_standardization": 0.95,   # è°ƒç”¨æ ‡å‡†åŒ–ç›®æ ‡
    "logic_clarity": 0.85,             # é€»è¾‘æ¸…æ™°åº¦ç›®æ ‡
    "professional_accuracy": 0.90,     # ä¸“ä¸šå‡†ç¡®æ€§ç›®æ ‡
}

SSAP_FOCUS_AREAS = [
    "architecture_design",      # æ¶æ„è®¾è®¡
    "workflow_orchestration",   # å·¥ä½œæµç¼–æ’
    "format_modules",           # æ ¼å¼æ¨¡å—
    "intelligent_collaboration" # æ™ºèƒ½ååŒ
]

def get_ssap_evaluation_config():
    """è·å–SSAPæ¡†æ¶ç‰¹å®šçš„è¯„ä¼°é…ç½®"""
    return {
        "check_architecture_format": True,
        "check_workflow_syntax": True,
        "check_format_modules": True,
        "check_calling_convention": True,
        "target_metrics": SSAP_QUALITY_METRICS,
        "focus_areas": SSAP_FOCUS_AREAS,
    }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºé…ç½®
    config = SSAPLoRAConfig(
        model_name="meta-llama/Llama-2-7b-hf",
        dataset_path="SSAP_LoRA_Dataset.json",
        output_dir="./ssap_lora_model",
        num_train_epochs=3,
        learning_rate=2e-4,
    )
    
    # è·å–LoRAå’Œè®­ç»ƒé…ç½®
    lora_config = get_lora_config(config)
    training_args = get_training_arguments(config)
    ssap_eval_config = get_ssap_evaluation_config()
    
    print("âœ… SSAP LoRAè®­ç»ƒé…ç½®å·²ç”Ÿæˆ")
    print(f"ğŸ“Š æ¨¡å‹: {config.model_name}")
    print(f"ğŸ“ æ•°æ®é›†: {config.dataset_path}")
    print(f"ğŸ¯ è¾“å‡ºç›®å½•: {config.output_dir}")
    print(f"âš™ï¸ LoRA Rank: {config.lora_r}")
    print(f"ğŸ“ˆ å­¦ä¹ ç‡: {config.learning_rate}")
    print(f"ğŸ”„ è®­ç»ƒè½®æ•°: {config.num_train_epochs}") 