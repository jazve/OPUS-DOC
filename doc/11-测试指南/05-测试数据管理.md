# 测试数据管理

## 🎯 测试数据管理概述

有效的测试数据管理确保测试的可重复性、准确性和维护性，是OPUS测试体系的重要基础。

## 📋 测试数据分类

### 静态测试数据
- **OPUS语法样本** - 各种语法结构示例
- **配置文件模板** - 标准配置模板
- **输入输出对** - 预期的输入输出关系
- **错误案例** - 各种异常情况样本

### 动态测试数据
- **随机生成数据** - 使用Faker生成
- **参数化数据** - pytest参数化测试数据
- **时间相关数据** - 基于当前时间生成
- **状态依赖数据** - 基于系统状态生成

### 敏感测试数据
- **脱敏用户数据** - 去除敏感信息的真实数据
- **模拟身份信息** - 虚构但真实的身份数据
- **测试API密钥** - 专用于测试的安全凭证

## 🗂️ 数据组织结构

### 目录结构
```
tests/fixtures/
├── static/                    # 静态测试数据
│   ├── opus_samples/         # OPUS语法样本
│   │   ├── valid/           # 有效语法
│   │   │   ├── basic.opus
│   │   │   ├── complex.opus
│   │   │   └── advanced.opus
│   │   └── invalid/         # 无效语法
│   │       ├── syntax_error.opus
│   │       └── missing_fields.opus
│   ├── configs/             # 配置文件
│   │   ├── default_config.json
│   │   ├── minimal_config.json
│   │   └── full_config.json
│   ├── inputs/              # 输入数据
│   │   ├── user_requests/
│   │   ├── requirements/
│   │   └── descriptions/
│   └── outputs/             # 期望输出
│       ├── agents/
│       ├── analyses/
│       └── responses/
├── dynamic/                  # 动态数据生成
│   ├── factories.py         # 工厂类
│   ├── generators.py        # 数据生成器
│   └── builders.py          # 数据构建器
├── schemas/                  # 数据模式
│   ├── opus_schema.json
│   ├── agent_schema.json
│   └── request_schema.json
└── utils/                    # 数据工具
    ├── data_loader.py
    ├── data_validator.py
    └── data_cleaner.py
```

## 📝 静态测试数据

### OPUS语法样本
```yaml
# tests/fixtures/static/opus_samples/valid/basic.opus
# Identity
name: 基础助手
role: AI助手
personality: 友好、专业
expertise: [通用知识, 问答]

# Architecture
knowledge_domains: [日常生活, 基础科学]
skills: [理解, 回答, 总结]

# Memory
type: session
retention: 1h

# Formats
response_style: 简洁明了
output_format: markdown

# Workflow
steps:
  - understand_query
  - retrieve_knowledge
  - generate_response

# Constraints
max_response_length: 500
language: 中文
```

```yaml
# tests/fixtures/static/opus_samples/valid/complex.opus
# Identity
name: 代码审查专家
role: 高级软件工程师
personality: 严谨、细致、建设性
expertise: [Python, JavaScript, Go, 代码质量, 架构设计]
communication_style: 专业、直接、教育性

# Architecture
knowledge_domains: 
  - 软件工程
  - 编程语言
  - 设计模式
  - 最佳实践
  - 性能优化
  - 安全编程

skills:
  - 代码分析
  - 问题识别
  - 改进建议
  - 文档生成
  - 架构评估

# Memory
type: long_term
retention: 30d
structure: hierarchical
categories:
  - user_preferences
  - code_patterns
  - review_history
  - best_practices

# Formats
response_style: 结构化、详细
output_format: 
  type: markdown
  sections: [摘要, 问题, 建议, 示例]
code_style: 
  highlighting: true
  line_numbers: true

# Workflow
steps:
  - code_analysis:
      - syntax_check
      - style_check
      - logic_analysis
      - security_scan
  - issue_identification:
      - categorize_issues
      - prioritize_severity
  - suggestion_generation:
      - provide_solutions
      - include_examples
  - report_creation:
      - structure_findings
      - format_output

# Constraints
max_response_length: 2000
supported_languages: [python, javascript, go, typescript]
review_depth: thorough
focus_areas: [性能, 安全, 可维护性, 可读性]
```

### 配置文件模板
```json
// tests/fixtures/static/configs/default_config.json
{
  "generator": {
    "max_complexity": 10,
    "default_language": "zh-CN",
    "output_format": "opus",
    "validation_level": "strict"
  },
  "parser": {
    "syntax_version": "1.0",
    "strict_mode": true,
    "error_tolerance": "none"
  },
  "memory": {
    "default_type": "session",
    "max_retention": "24h",
    "cleanup_interval": "1h"
  },
  "constraints": {
    "max_response_length": 1000,
    "allowed_formats": ["markdown", "json", "plain"],
    "security_level": "standard"
  }
}
```

## 🏭 动态数据生成

### 数据工厂 (Factory)
```python
# tests/fixtures/dynamic/factories.py
import factory
from faker import Faker
from opus.core import Identity, Architecture, Memory, Agent
import random

fake = Faker('zh_CN')

class IdentityFactory(factory.Factory):
    """身份数据工厂"""
    
    class Meta:
        model = Identity
    
    name = factory.LazyFunction(lambda: fake.name() + "助手")
    role = factory.Iterator([
        "AI助手", "专业顾问", "技术专家", 
        "学习助手", "创作助手", "分析师"
    ])
    personality = factory.LazyFunction(
        lambda: random.choice([
            "友好、耐心", "专业、严谨", "创新、开放",
            "细致、认真", "幽默、轻松", "智慧、深度"
        ])
    )
    expertise = factory.LazyFunction(
        lambda: random.sample([
            "Python", "JavaScript", "数据分析", "机器学习",
            "Web开发", "移动开发", "云计算", "区块链",
            "产品设计", "用户体验", "项目管理", "商业分析"
        ], k=random.randint(2, 5))
    )

class ArchitectureFactory(factory.Factory):
    """架构数据工厂"""
    
    class Meta:
        model = Architecture
    
    knowledge_domains = factory.LazyFunction(
        lambda: random.sample([
            "技术", "科学", "商业", "教育", "娱乐",
            "健康", "金融", "法律", "艺术", "体育"
        ], k=random.randint(2, 4))
    )
    skills = factory.LazyFunction(
        lambda: random.sample([
            "分析", "生成", "总结", "翻译", "推理",
            "创作", "计算", "检索", "验证", "优化"
        ], k=random.randint(3, 6))
    )

class MemoryFactory(factory.Factory):
    """记忆数据工厂"""
    
    class Meta:
        model = Memory
    
    type = factory.Iterator(["session", "short_term", "long_term"])
    retention = factory.LazyFunction(
        lambda: random.choice(["1h", "6h", "1d", "7d", "30d"])
    )
    structure = factory.Iterator(["flat", "hierarchical", "graph"])

class AgentFactory(factory.Factory):
    """智能体数据工厂"""
    
    class Meta:
        model = Agent
    
    identity = factory.SubFactory(IdentityFactory)
    architecture = factory.SubFactory(ArchitectureFactory)
    memory = factory.SubFactory(MemoryFactory)

class RequestFactory(factory.Factory):
    """请求数据工厂"""
    
    class Meta:
        model = dict
    
    description = factory.LazyFunction(
        lambda: fake.text(max_nb_chars=200)
    )
    requirements = factory.LazyFunction(
        lambda: [fake.sentence() for _ in range(random.randint(1, 5))]
    )
    type = factory.Iterator(["basic", "advanced", "expert"])
    complexity = factory.Iterator(["low", "medium", "high"])
```

### 数据生成器
```python
# tests/fixtures/dynamic/generators.py
import random
import string
from datetime import datetime, timedelta
from typing import List, Dict, Any

class OpusGenerator:
    """OPUS语法生成器"""
    
    def __init__(self):
        self.names = [
            "智能助手", "专业顾问", "学习伙伴", "创作助手",
            "数据分析师", "代码专家", "设计师", "翻译官"
        ]
        self.roles = [
            "AI助手", "技术专家", "领域顾问", "创意总监",
            "数据科学家", "软件工程师", "产品经理", "研究员"
        ]
        self.personalities = [
            "友好、专业", "严谨、细致", "创新、开放", "耐心、细心",
            "幽默、轻松", "深度、智慧", "热情、积极", "冷静、理性"
        ]
    
    def generate_identity_section(self) -> str:
        """生成Identity段落"""
        name = random.choice(self.names)
        role = random.choice(self.roles)
        personality = random.choice(self.personalities)
        expertise = random.sample([
            "Python", "JavaScript", "数据分析", "机器学习",
            "Web开发", "移动开发", "云计算", "产品设计"
        ], k=random.randint(2, 4))
        
        return f"""# Identity
name: {name}
role: {role}
personality: {personality}
expertise: {expertise}"""
    
    def generate_architecture_section(self) -> str:
        """生成Architecture段落"""
        domains = random.sample([
            "技术", "科学", "商业", "教育", "健康", "金融"
        ], k=random.randint(2, 4))
        skills = random.sample([
            "分析", "生成", "总结", "翻译", "推理", "创作"
        ], k=random.randint(3, 5))
        
        return f"""# Architecture
knowledge_domains: {domains}
skills: {skills}"""
    
    def generate_memory_section(self) -> str:
        """生成Memory段落"""
        mem_type = random.choice(["session", "short_term", "long_term"])
        retention = random.choice(["1h", "6h", "1d", "7d", "30d"])
        
        return f"""# Memory
type: {mem_type}
retention: {retention}"""
    
    def generate_complete_opus(self) -> str:
        """生成完整的OPUS文件"""
        sections = [
            self.generate_identity_section(),
            self.generate_architecture_section(),
            self.generate_memory_section()
        ]
        
        return "\n\n".join(sections)

class TestDataGenerator:
    """通用测试数据生成器"""
    
    @staticmethod
    def generate_user_requests(count: int = 10) -> List[Dict[str, Any]]:
        """生成用户请求数据"""
        templates = [
            "我需要一个{domain}领域的{type}助手",
            "帮我创建一个能够{skill}的AI助手",
            "我想要一个专门处理{task}的智能助手",
            "需要一个{personality}的{role}来帮助我"
        ]
        
        domains = ["技术", "商业", "教育", "健康", "金融", "设计"]
        types = ["专业", "智能", "高效", "创新", "专门"]
        skills = ["分析数据", "生成内容", "解决问题", "提供建议"]
        tasks = ["客户服务", "内容创作", "数据分析", "项目管理"]
        personalities = ["友好", "专业", "耐心", "创新"]
        roles = ["顾问", "助手", "专家", "指导师"]
        
        requests = []
        for i in range(count):
            template = random.choice(templates)
            description = template.format(
                domain=random.choice(domains),
                type=random.choice(types),
                skill=random.choice(skills),
                task=random.choice(tasks),
                personality=random.choice(personalities),
                role=random.choice(roles)
            )
            
            requests.append({
                "id": f"req_{i+1:03d}",
                "description": description,
                "requirements": [
                    f"能够{random.choice(skills)}",
                    f"具备{random.choice(personalities)}的特质",
                    f"专业的{random.choice(domains)}知识"
                ],
                "complexity": random.choice(["low", "medium", "high"]),
                "created_at": datetime.now() - timedelta(
                    days=random.randint(0, 30)
                )
            })
        
        return requests
    
    @staticmethod
    def generate_error_cases() -> List[Dict[str, Any]]:
        """生成错误案例"""
        return [
            {
                "name": "missing_identity_name",
                "opus_content": """
                # Identity
                role: AI助手
                """,
                "expected_error": "name is required"
            },
            {
                "name": "invalid_memory_type",
                "opus_content": """
                # Memory
                type: invalid_type
                """,
                "expected_error": "invalid memory type"
            },
            {
                "name": "malformed_yaml",
                "opus_content": """
                # Identity
                name: [无效格式
                """,
                "expected_error": "YAML parsing error"
            }
        ]
```

### 数据构建器
```python
# tests/fixtures/dynamic/builders.py
from typing import Dict, List, Any, Optional

class AgentConfigBuilder:
    """智能体配置构建器"""
    
    def __init__(self):
        self.config = {}
    
    def with_identity(self, name: str, role: str, **kwargs) -> 'AgentConfigBuilder':
        """添加身份配置"""
        self.config['identity'] = {
            'name': name,
            'role': role,
            **kwargs
        }
        return self
    
    def with_architecture(self, domains: List[str], skills: List[str]) -> 'AgentConfigBuilder':
        """添加架构配置"""
        self.config['architecture'] = {
            'knowledge_domains': domains,
            'skills': skills
        }
        return self
    
    def with_memory(self, mem_type: str, retention: str = "1h") -> 'AgentConfigBuilder':
        """添加记忆配置"""
        self.config['memory'] = {
            'type': mem_type,
            'retention': retention
        }
        return self
    
    def with_workflow(self, steps: List[str]) -> 'AgentConfigBuilder':
        """添加工作流配置"""
        self.config['workflow'] = {
            'steps': steps
        }
        return self
    
    def with_constraints(self, **constraints) -> 'AgentConfigBuilder':
        """添加约束配置"""
        self.config['constraints'] = constraints
        return self
    
    def build(self) -> Dict[str, Any]:
        """构建最终配置"""
        return self.config.copy()

class TestScenarioBuilder:
    """测试场景构建器"""
    
    def __init__(self):
        self.scenario = {
            'name': '',
            'description': '',
            'inputs': {},
            'expected_outputs': {},
            'setup': [],
            'teardown': [],
            'assertions': []
        }
    
    def named(self, name: str) -> 'TestScenarioBuilder':
        """设置场景名称"""
        self.scenario['name'] = name
        return self
    
    def described(self, description: str) -> 'TestScenarioBuilder':
        """设置场景描述"""
        self.scenario['description'] = description
        return self
    
    def with_input(self, key: str, value: Any) -> 'TestScenarioBuilder':
        """添加输入数据"""
        self.scenario['inputs'][key] = value
        return self
    
    def expects_output(self, key: str, value: Any) -> 'TestScenarioBuilder':
        """添加期望输出"""
        self.scenario['expected_outputs'][key] = value
        return self
    
    def setup_step(self, step: str) -> 'TestScenarioBuilder':
        """添加设置步骤"""
        self.scenario['setup'].append(step)
        return self
    
    def teardown_step(self, step: str) -> 'TestScenarioBuilder':
        """添加清理步骤"""
        self.scenario['teardown'].append(step)
        return self
    
    def assert_that(self, assertion: str) -> 'TestScenarioBuilder':
        """添加断言"""
        self.scenario['assertions'].append(assertion)
        return self
    
    def build(self) -> Dict[str, Any]:
        """构建测试场景"""
        return self.scenario.copy()

# 使用示例
def create_code_reviewer_config():
    """创建代码审查助手配置"""
    return (AgentConfigBuilder()
            .with_identity("代码审查专家", "高级软件工程师", 
                         personality="严谨、专业")
            .with_architecture(
                domains=["软件工程", "代码质量", "最佳实践"],
                skills=["代码分析", "问题识别", "改进建议"]
            )
            .with_memory("long_term", "30d")
            .with_workflow([
                "code_analysis", "issue_identification", 
                "suggestion_generation", "report_creation"
            ])
            .with_constraints(
                max_response_length=2000,
                supported_languages=["python", "javascript", "go"]
            )
            .build())

def create_agent_generation_scenario():
    """创建智能体生成测试场景"""
    return (TestScenarioBuilder()
            .named("智能体生成基础场景")
            .described("测试基础智能体生成功能")
            .with_input("description", "Python代码审查助手")
            .with_input("requirements", ["代码分析", "改进建议"])
            .expects_output("agent_type", "code_reviewer")
            .expects_output("complexity", "medium")
            .setup_step("初始化生成器")
            .teardown_step("清理临时文件")
            .assert_that("生成的智能体包含代码分析能力")
            .assert_that("生成的智能体具有专业人设")
            .build())
```

## 🔧 数据管理工具

### 数据加载器
```python
# tests/fixtures/utils/data_loader.py
import json
import yaml
import os
from pathlib import Path
from typing import Dict, List, Any, Optional

class TestDataLoader:
    """测试数据加载器"""
    
    def __init__(self, fixtures_dir: str = "tests/fixtures"):
        self.fixtures_dir = Path(fixtures_dir)
    
    def load_opus_samples(self, category: str = "valid") -> Dict[str, str]:
        """加载OPUS语法样本"""
        samples_dir = self.fixtures_dir / "static" / "opus_samples" / category
        samples = {}
        
        for opus_file in samples_dir.glob("*.opus"):
            with open(opus_file, 'r', encoding='utf-8') as f:
                samples[opus_file.stem] = f.read()
        
        return samples
    
    def load_config(self, config_name: str) -> Dict[str, Any]:
        """加载配置文件"""
        config_path = self.fixtures_dir / "static" / "configs" / f"{config_name}.json"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def load_test_scenarios(self, scenario_type: str) -> List[Dict[str, Any]]:
        """加载测试场景"""
        scenario_path = self.fixtures_dir / "scenarios" / f"{scenario_type}.yaml"
        
        with open(scenario_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def load_input_output_pairs(self, test_type: str) -> List[Dict[str, Any]]:
        """加载输入输出对"""
        inputs_dir = self.fixtures_dir / "static" / "inputs" / test_type
        outputs_dir = self.fixtures_dir / "static" / "outputs" / test_type
        
        pairs = []
        for input_file in inputs_dir.glob("*.json"):
            output_file = outputs_dir / input_file.name
            
            if output_file.exists():
                with open(input_file, 'r', encoding='utf-8') as f:
                    input_data = json.load(f)
                
                with open(output_file, 'r', encoding='utf-8') as f:
                    output_data = json.load(f)
                
                pairs.append({
                    "name": input_file.stem,
                    "input": input_data,
                    "expected_output": output_data
                })
        
        return pairs
    
    def get_error_cases(self) -> List[Dict[str, Any]]:
        """获取错误案例"""
        error_cases_path = self.fixtures_dir / "static" / "error_cases.json"
        
        with open(error_cases_path, 'r', encoding='utf-8') as f:
            return json.load(f)
```

### 数据验证器
```python
# tests/fixtures/utils/data_validator.py
import jsonschema
from typing import Dict, Any, List
from pathlib import Path

class TestDataValidator:
    """测试数据验证器"""
    
    def __init__(self, schemas_dir: str = "tests/fixtures/schemas"):
        self.schemas_dir = Path(schemas_dir)
        self.schemas = self._load_schemas()
    
    def _load_schemas(self) -> Dict[str, Dict[str, Any]]:
        """加载所有模式文件"""
        schemas = {}
        
        for schema_file in self.schemas_dir.glob("*.json"):
            with open(schema_file, 'r', encoding='utf-8') as f:
                schemas[schema_file.stem] = json.load(f)
        
        return schemas
    
    def validate_opus_syntax(self, opus_content: str) -> Dict[str, Any]:
        """验证OPUS语法"""
        # 这里需要实现OPUS语法验证逻辑
        result = {
            "valid": True,
            "errors": [],
            "warnings": []
        }
        
        # 基础验证
        if not opus_content.strip():
            result["valid"] = False
            result["errors"].append("OPUS content cannot be empty")
        
        # 检查必需的段落
        required_sections = ["# Identity"]
        for section in required_sections:
            if section not in opus_content:
                result["valid"] = False
                result["errors"].append(f"Missing required section: {section}")
        
        return result
    
    def validate_agent_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """验证智能体配置"""
        try:
            jsonschema.validate(config, self.schemas["agent_schema"])
            return {"valid": True, "errors": []}
        except jsonschema.ValidationError as e:
            return {"valid": False, "errors": [str(e)]}
    
    def validate_test_data_integrity(self, test_data_dir: str) -> Dict[str, Any]:
        """验证测试数据完整性"""
        results = {
            "valid": True,
            "issues": [],
            "statistics": {}
        }
        
        data_dir = Path(test_data_dir)
        
        # 检查目录结构
        required_dirs = ["static", "dynamic", "schemas", "utils"]
        for dir_name in required_dirs:
            if not (data_dir / dir_name).exists():
                results["valid"] = False
                results["issues"].append(f"Missing directory: {dir_name}")
        
        # 统计文件数量
        results["statistics"] = {
            "opus_samples": len(list(data_dir.glob("static/opus_samples/**/*.opus"))),
            "config_files": len(list(data_dir.glob("static/configs/*.json"))),
            "schema_files": len(list(data_dir.glob("schemas/*.json")))
        }
        
        return results
```

## 📊 数据版本管理

### 数据版本控制
```python
# tests/fixtures/utils/data_versioning.py
import hashlib
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

class TestDataVersionManager:
    """测试数据版本管理器"""
    
    def __init__(self, data_dir: str = "tests/fixtures"):
        self.data_dir = Path(data_dir)
        self.version_file = self.data_dir / ".data_version.json"
    
    def calculate_data_hash(self, file_path: Path) -> str:
        """计算文件哈希"""
        hasher = hashlib.md5()
        
        if file_path.is_file():
            with open(file_path, 'rb') as f:
                hasher.update(f.read())
        
        return hasher.hexdigest()
    
    def scan_data_changes(self) -> Dict[str, Any]:
        """扫描数据变更"""
        current_version = self.load_version_info()
        new_version = {
            "version": current_version.get("version", 0) + 1,
            "timestamp": datetime.now().isoformat(),
            "files": {}
        }
        
        # 扫描所有数据文件
        for file_path in self.data_dir.rglob("*"):
            if file_path.is_file() and not file_path.name.startswith("."):
                relative_path = str(file_path.relative_to(self.data_dir))
                file_hash = self.calculate_data_hash(file_path)
                
                new_version["files"][relative_path] = {
                    "hash": file_hash,
                    "size": file_path.stat().st_size,
                    "modified": datetime.fromtimestamp(
                        file_path.stat().st_mtime
                    ).isoformat()
                }
        
        # 比较变更
        changes = self.compare_versions(current_version, new_version)
        new_version["changes"] = changes
        
        return new_version
    
    def load_version_info(self) -> Dict[str, Any]:
        """加载版本信息"""
        if self.version_file.exists():
            with open(self.version_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"version": 0, "files": {}}
    
    def save_version_info(self, version_info: Dict[str, Any]):
        """保存版本信息"""
        with open(self.version_file, 'w', encoding='utf-8') as f:
            json.dump(version_info, f, indent=2, ensure_ascii=False)
    
    def compare_versions(self, old_version: Dict[str, Any], 
                        new_version: Dict[str, Any]) -> Dict[str, List[str]]:
        """比较版本差异"""
        old_files = old_version.get("files", {})
        new_files = new_version.get("files", {})
        
        changes = {
            "added": [],
            "modified": [],
            "deleted": []
        }
        
        # 找出新增和修改的文件
        for file_path, file_info in new_files.items():
            if file_path not in old_files:
                changes["added"].append(file_path)
            elif old_files[file_path]["hash"] != file_info["hash"]:
                changes["modified"].append(file_path)
        
        # 找出删除的文件
        for file_path in old_files:
            if file_path not in new_files:
                changes["deleted"].append(file_path)
        
        return changes
    
    def create_snapshot(self, description: str = "") -> str:
        """创建数据快照"""
        version_info = self.scan_data_changes()
        version_info["description"] = description
        
        # 保存版本信息
        self.save_version_info(version_info)
        
        # 创建快照目录
        snapshot_dir = self.data_dir.parent / "snapshots" / f"v{version_info['version']}"
        snapshot_dir.mkdir(parents=True, exist_ok=True)
        
        # 复制数据文件
        import shutil
        shutil.copytree(self.data_dir, snapshot_dir / "data", 
                       ignore=shutil.ignore_patterns(".*", "snapshots"))
        
        return str(snapshot_dir)
```

## 🧹 数据清理和维护

### 数据清理工具
```python
# tests/fixtures/utils/data_cleaner.py
import os
import json
from pathlib import Path
from typing import Set, List, Dict, Any

class TestDataCleaner:
    """测试数据清理工具"""
    
    def __init__(self, fixtures_dir: str = "tests/fixtures"):
        self.fixtures_dir = Path(fixtures_dir)
    
    def clean_orphaned_files(self) -> Dict[str, List[str]]:
        """清理孤立文件"""
        results = {
            "removed": [],
            "errors": []
        }
        
        # 查找孤立的输出文件（没有对应输入文件）
        inputs_dir = self.fixtures_dir / "static" / "inputs"
        outputs_dir = self.fixtures_dir / "static" / "outputs"
        
        if outputs_dir.exists():
            for category_dir in outputs_dir.iterdir():
                if category_dir.is_dir():
                    input_category = inputs_dir / category_dir.name
                    
                    for output_file in category_dir.glob("*.json"):
                        input_file = input_category / output_file.name
                        
                        if not input_file.exists():
                            try:
                                output_file.unlink()
                                results["removed"].append(str(output_file))
                            except Exception as e:
                                results["errors"].append(f"Failed to remove {output_file}: {e}")
        
        return results
    
    def validate_file_consistency(self) -> Dict[str, Any]:
        """验证文件一致性"""
        issues = {
            "missing_outputs": [],
            "invalid_json": [],
            "encoding_errors": []
        }
        
        # 检查输入输出对的一致性
        inputs_dir = self.fixtures_dir / "static" / "inputs"
        outputs_dir = self.fixtures_dir / "static" / "outputs"
        
        for category_dir in inputs_dir.iterdir():
            if category_dir.is_dir():
                output_category = outputs_dir / category_dir.name
                
                for input_file in category_dir.glob("*.json"):
                    output_file = output_category / input_file.name
                    
                    # 检查是否有对应的输出文件
                    if not output_file.exists():
                        issues["missing_outputs"].append(str(input_file))
                    
                    # 验证JSON格式
                    try:
                        with open(input_file, 'r', encoding='utf-8') as f:
                            json.load(f)
                    except json.JSONDecodeError:
                        issues["invalid_json"].append(str(input_file))
                    except UnicodeDecodeError:
                        issues["encoding_errors"].append(str(input_file))
        
        return issues
    
    def optimize_storage(self) -> Dict[str, Any]:
        """优化存储空间"""
        results = {
            "compressed_files": [],
            "space_saved": 0,
            "errors": []
        }
        
        # 压缩大型JSON文件
        for json_file in self.fixtures_dir.rglob("*.json"):
            if json_file.stat().st_size > 10240:  # 大于10KB
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # 重新写入，移除多余空格
                    original_size = json_file.stat().st_size
                    
                    with open(json_file, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, separators=(',', ':'))
                    
                    new_size = json_file.stat().st_size
                    space_saved = original_size - new_size
                    
                    if space_saved > 0:
                        results["compressed_files"].append(str(json_file))
                        results["space_saved"] += space_saved
                
                except Exception as e:
                    results["errors"].append(f"Failed to compress {json_file}: {e}")
        
        return results
```

## 🎓 最佳实践

### 数据管理原则
1. **版本控制** - 所有测试数据纳入版本控制
2. **数据隔离** - 测试数据与生产数据完全隔离
3. **定期维护** - 定期清理和更新测试数据
4. **文档记录** - 每个数据集都有清晰的文档说明

### 常见问题
- ❌ **数据污染** - 测试间数据相互影响
- ❌ **数据过时** - 长期未更新的测试数据
- ❌ **缺乏文档** - 数据用途和格式不明确
- ❌ **版本混乱** - 不同版本数据混用

## 📚 相关文档

- [测试概述](01-测试概述.md) - 整体测试策略
- [单元测试指南](02-单元测试.md) - 单元测试方法
- [集成测试指南](03-集成测试.md) - 集成测试策略
- [自动化测试](06-自动化测试.md) - CI/CD集成

---

*🎯 良好的测试数据管理是保证测试质量和效率的基础。*