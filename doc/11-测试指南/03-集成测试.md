# é›†æˆæµ‹è¯•æŒ‡å—

## ğŸ¯ é›†æˆæµ‹è¯•æ¦‚è¿°

é›†æˆæµ‹è¯•éªŒè¯OPUSç³»ç»Ÿä¸­å¤šä¸ªç»„ä»¶ååŒå·¥ä½œçš„æ­£ç¡®æ€§ï¼Œç¡®ä¿æ¨¡å—é—´æ¥å£å’Œæ•°æ®æµçš„ç¨³å®šæ€§ã€‚

## ğŸ“‹ é›†æˆæµ‹è¯•èŒƒå›´

### æ¨¡å—é—´é›†æˆ
- **Identity + Architecture** - èº«ä»½ä¸æ¶æ„é…ç½®é›†æˆ
- **Memory + Workflow** - è®°å¿†ä¸å·¥ä½œæµåä½œ
- **Formats + Constraints** - æ ¼å¼åŒ–ä¸çº¦æŸéªŒè¯
- **Parser + Generator** - è§£æå™¨ä¸ç”Ÿæˆå™¨é›†æˆ

### å¤–éƒ¨ç³»ç»Ÿé›†æˆ
- **MCPæœåŠ¡é›†æˆ** - Model Context Protocol
- **RAGç³»ç»Ÿé›†æˆ** - æ£€ç´¢å¢å¼ºç”Ÿæˆ
- **å¤–éƒ¨APIé›†æˆ** - ç¬¬ä¸‰æ–¹æœåŠ¡æ¥å£
- **æ•°æ®åº“é›†æˆ** - æŒä¹…åŒ–å­˜å‚¨

### ç«¯åˆ°ç«¯æµç¨‹
- **æ™ºèƒ½ä½“ç”Ÿæˆæµç¨‹** - ä»éœ€æ±‚åˆ°è¾“å‡ºçš„å®Œæ•´æµç¨‹
- **ç”¨æˆ·äº¤äº’æµç¨‹** - ç”¨æˆ·ç•Œé¢åˆ°åç«¯å¤„ç†
- **é…ç½®åŠ è½½æµç¨‹** - é…ç½®æ–‡ä»¶åˆ°ç³»ç»Ÿåˆå§‹åŒ–

## ğŸ› ï¸ æµ‹è¯•æ¡†æ¶é…ç½®

### Pythoné›†æˆæµ‹è¯•ç¯å¢ƒ
```python
# requirements-integration.txt
pytest>=7.0.0
pytest-asyncio>=0.21.0
pytest-mock>=3.0.0
httpx>=0.24.0
testcontainers>=3.7.0
docker>=6.0.0
requests>=2.28.0
```

### æµ‹è¯•é…ç½®
```ini
# pytest.ini (é›†æˆæµ‹è¯•éƒ¨åˆ†)
[tool:pytest]
markers =
    integration: marks tests as integration tests
    slow: marks tests as slow running
    external: marks tests that require external dependencies
    database: marks tests that require database
    api: marks tests that call external APIs

addopts = 
    -m "not slow"  # é»˜è®¤è·³è¿‡æ…¢é€Ÿæµ‹è¯•
    --tb=short
    -v
```

### ç›®å½•ç»“æ„
```
tests/integration/
â”œâ”€â”€ conftest.py
â”œâ”€â”€ test_module_integration.py
â”œâ”€â”€ test_external_services.py
â”œâ”€â”€ test_end_to_end_workflows.py
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ test_mcp_integration.py
â”‚   â”œâ”€â”€ test_rag_integration.py
â”‚   â””â”€â”€ test_external_apis.py
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ test_memory_persistence.py
â”‚   â””â”€â”€ test_config_storage.py
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ test_agent_generation.py
â”‚   â”œâ”€â”€ test_user_interaction.py
â”‚   â””â”€â”€ test_configuration_loading.py
â””â”€â”€ fixtures/
    â”œâ”€â”€ sample_configs/
    â”œâ”€â”€ mock_responses/
    â””â”€â”€ test_data/
```

## ğŸ­ é›†æˆæµ‹è¯•ç­–ç•¥

### å¥‘çº¦æµ‹è¯•
```python
class TestModuleContracts:
    """æ¨¡å—é—´å¥‘çº¦æµ‹è¯•"""
    
    def test_identity_architecture_contract(self):
        """æµ‹è¯•Identityå’ŒArchitectureæ¨¡å—é—´çš„å¥‘çº¦"""
        # Given
        identity = Identity(name="æµ‹è¯•åŠ©æ‰‹", role="AIåŠ©æ‰‹")
        architecture_config = {
            "knowledge_domains": ["AI", "Python"],
            "skills": ["åˆ†æ", "ç”Ÿæˆ"]
        }
        
        # When
        architecture = Architecture.from_identity(identity, architecture_config)
        
        # Then
        assert architecture.is_compatible_with(identity)
        assert architecture.knowledge_domains == ["AI", "Python"]
```

### æ•°æ®æµæµ‹è¯•
```python
class TestDataFlow:
    """æ•°æ®æµé›†æˆæµ‹è¯•"""
    
    @pytest.mark.integration
    def test_complete_agent_generation_flow(self):
        """æµ‹è¯•å®Œæ•´çš„æ™ºèƒ½ä½“ç”Ÿæˆæ•°æ®æµ"""
        # Given
        user_input = "æˆ‘éœ€è¦ä¸€ä¸ªPythonä»£ç å®¡æŸ¥åŠ©æ‰‹"
        
        # When - æ¨¡æ‹Ÿå®Œæ•´æµç¨‹
        analyzer = RequirementAnalyzer()
        analysis = analyzer.analyze(user_input)
        
        generator = AgentGenerator()
        agent_config = generator.generate_config(analysis)
        
        agent = Agent.from_config(agent_config)
        
        # Then
        assert analysis.agent_type == "code_reviewer"
        assert "Python" in agent.identity.expertise
        assert agent.workflow.has_step("code_analysis")
```

## ğŸŒ å¤–éƒ¨æœåŠ¡é›†æˆæµ‹è¯•

### MCPé›†æˆæµ‹è¯•
```python
class TestMCPIntegration:
    """MCPæœåŠ¡é›†æˆæµ‹è¯•"""
    
    @pytest.mark.external
    @pytest.mark.asyncio
    async def test_mcp_server_connection(self):
        """æµ‹è¯•MCPæœåŠ¡å™¨è¿æ¥"""
        # Given
        mcp_config = {
            "server_url": "http://localhost:8080",
            "protocols": ["v1.0"]
        }
        
        # When
        async with MCPClient(mcp_config) as client:
            capabilities = await client.get_capabilities()
        
        # Then
        assert capabilities.is_available()
        assert "tools" in capabilities.features
    
    @pytest.mark.external
    def test_mcp_tool_execution(self):
        """æµ‹è¯•MCPå·¥å…·æ‰§è¡Œ"""
        # Given
        mcp_client = MCPClient(test_config)
        tool_request = {
            "name": "code_analyzer",
            "parameters": {"code": "def hello(): print('world')"}
        }
        
        # When
        result = mcp_client.execute_tool(tool_request)
        
        # Then
        assert result.success
        assert "analysis" in result.data
```

### RAGç³»ç»Ÿé›†æˆæµ‹è¯•
```python
class TestRAGIntegration:
    """RAGç³»ç»Ÿé›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def mock_vector_db(self):
        """æ¨¡æ‹Ÿå‘é‡æ•°æ®åº“"""
        return MockVectorDB()
    
    def test_rag_knowledge_retrieval(self, mock_vector_db):
        """æµ‹è¯•RAGçŸ¥è¯†æ£€ç´¢"""
        # Given
        rag_system = RAGSystem(vector_db=mock_vector_db)
        query = "Pythonæœ€ä½³å®è·µ"
        
        # When
        results = rag_system.retrieve(query, top_k=5)
        
        # Then
        assert len(results) <= 5
        assert all(result.relevance_score > 0.5 for result in results)
    
    @pytest.mark.integration
    def test_rag_enhanced_generation(self):
        """æµ‹è¯•RAGå¢å¼ºçš„ç”Ÿæˆè¿‡ç¨‹"""
        # Given
        generator = RAGEnhancedGenerator()
        context = "éœ€è¦Pythonä»£ç å®¡æŸ¥å»ºè®®"
        
        # When
        response = generator.generate_with_rag(context)
        
        # Then
        assert response.has_context_citations()
        assert response.content_quality > 0.8
```

## ğŸ—„ï¸ æ•°æ®åº“é›†æˆæµ‹è¯•

### æµ‹è¯•æ•°æ®åº“è®¾ç½®
```python
# conftest.py
import pytest
from testcontainers.postgres import PostgresContainer

@pytest.fixture(scope="session")
def test_database():
    """åˆ›å»ºæµ‹è¯•æ•°æ®åº“å®¹å™¨"""
    with PostgresContainer("postgres:13") as postgres:
        db_url = postgres.get_connection_url()
        
        # åˆå§‹åŒ–æ•°æ®åº“ç»“æ„
        init_test_database(db_url)
        
        yield db_url

@pytest.fixture
def clean_database(test_database):
    """æ¯ä¸ªæµ‹è¯•å‰æ¸…ç†æ•°æ®åº“"""
    cleanup_database(test_database)
    yield test_database
    cleanup_database(test_database)
```

### æŒä¹…åŒ–æµ‹è¯•
```python
class TestMemoryPersistence:
    """è®°å¿†æŒä¹…åŒ–é›†æˆæµ‹è¯•"""
    
    def test_memory_save_and_load(self, clean_database):
        """æµ‹è¯•è®°å¿†ä¿å­˜å’ŒåŠ è½½"""
        # Given
        memory = Memory(
            type="long_term",
            content={"user_preferences": "ç®€æ´å›ç­”"},
            metadata={"created_at": "2024-01-01"}
        )
        
        # When - ä¿å­˜
        memory_id = memory.save(clean_database)
        
        # Then - åŠ è½½éªŒè¯
        loaded_memory = Memory.load(memory_id, clean_database)
        assert loaded_memory.content == memory.content
        assert loaded_memory.type == "long_term"
```

## ğŸ”„ å·¥ä½œæµé›†æˆæµ‹è¯•

### ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•
```python
class TestEndToEndWorkflows:
    """ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•"""
    
    @pytest.mark.slow
    @pytest.mark.integration
    def test_complete_agent_creation_workflow(self):
        """æµ‹è¯•å®Œæ•´çš„æ™ºèƒ½ä½“åˆ›å»ºå·¥ä½œæµ"""
        # Given
        user_request = {
            "description": "æˆ‘éœ€è¦ä¸€ä¸ªä¸“ä¸šçš„Pythonä»£ç å®¡æŸ¥åŠ©æ‰‹",
            "requirements": [
                "èƒ½å¤Ÿåˆ†æä»£ç è´¨é‡",
                "æä¾›æ”¹è¿›å»ºè®®",
                "æ”¯æŒå¤šç§ç¼–ç¨‹èŒƒå¼"
            ]
        }
        
        # When - æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
        workflow = AgentCreationWorkflow()
        
        # 1. éœ€æ±‚åˆ†æ
        analysis_result = workflow.analyze_requirements(user_request)
        
        # 2. æ™ºèƒ½ä½“é…ç½®ç”Ÿæˆ
        agent_config = workflow.generate_agent_config(analysis_result)
        
        # 3. æ™ºèƒ½ä½“å®ä¾‹åŒ–
        agent = workflow.create_agent(agent_config)
        
        # 4. éªŒè¯å’Œæµ‹è¯•
        validation_result = workflow.validate_agent(agent)
        
        # Then
        assert analysis_result.confidence > 0.8
        assert agent_config.is_valid()
        assert agent.is_ready()
        assert validation_result.all_tests_passed()
    
    def test_error_handling_in_workflow(self):
        """æµ‹è¯•å·¥ä½œæµä¸­çš„é”™è¯¯å¤„ç†"""
        # Given
        invalid_request = {"description": ""}  # æ— æ•ˆè¯·æ±‚
        
        # When
        workflow = AgentCreationWorkflow()
        
        with pytest.raises(ValidationError) as exc_info:
            workflow.analyze_requirements(invalid_request)
        
        # Then
        assert "description cannot be empty" in str(exc_info.value)
```

## ğŸ”§ æ¨¡æ‹Ÿå’Œå­˜æ ¹

### å¤–éƒ¨ä¾èµ–æ¨¡æ‹Ÿ
```python
class TestWithMockedDependencies:
    """ä½¿ç”¨æ¨¡æ‹Ÿä¾èµ–çš„é›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def mock_external_services(self):
        """æ¨¡æ‹Ÿæ‰€æœ‰å¤–éƒ¨æœåŠ¡"""
        with patch.multiple(
            'opus.external',
            openai_client=Mock(),
            vector_db=Mock(),
            mcp_server=Mock()
        ) as mocks:
            # é…ç½®æ¨¡æ‹Ÿè¡Œä¸º
            mocks['openai_client'].generate.return_value = "AIç”Ÿæˆå†…å®¹"
            mocks['vector_db'].search.return_value = [{"doc": "ç›¸å…³æ–‡æ¡£"}]
            mocks['mcp_server'].execute.return_value = {"result": "æ‰§è¡ŒæˆåŠŸ"}
            
            yield mocks
    
    def test_integrated_generation_with_mocks(self, mock_external_services):
        """ä½¿ç”¨æ¨¡æ‹ŸæœåŠ¡æµ‹è¯•é›†æˆç”Ÿæˆ"""
        # Given
        generator = IntegratedGenerator()
        request = GenerationRequest(type="agent", description="æµ‹è¯•åŠ©æ‰‹")
        
        # When
        result = generator.generate(request)
        
        # Then
        assert result.success
        mock_external_services['openai_client'].generate.assert_called_once()
```

## ğŸ“Š æ€§èƒ½é›†æˆæµ‹è¯•

### è´Ÿè½½æµ‹è¯•
```python
import pytest
from concurrent.futures import ThreadPoolExecutor
import time

class TestPerformanceIntegration:
    """æ€§èƒ½é›†æˆæµ‹è¯•"""
    
    @pytest.mark.slow
    def test_concurrent_agent_generation(self):
        """æµ‹è¯•å¹¶å‘æ™ºèƒ½ä½“ç”Ÿæˆæ€§èƒ½"""
        # Given
        requests = [
            {"description": f"åŠ©æ‰‹{i}"} 
            for i in range(10)
        ]
        
        # When
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [
                executor.submit(self._generate_agent, req) 
                for req in requests
            ]
            results = [future.result() for future in futures]
        
        end_time = time.time()
        
        # Then
        assert all(result.success for result in results)
        assert end_time - start_time < 60  # 60ç§’å†…å®Œæˆ
    
    def _generate_agent(self, request):
        """ç”Ÿæˆå•ä¸ªæ™ºèƒ½ä½“"""
        generator = AgentGenerator()
        return generator.generate(request)
```

## ğŸš¦ æµ‹è¯•æ‰§è¡Œå’Œç¯å¢ƒ

### DockeråŒ–æµ‹è¯•ç¯å¢ƒ
```dockerfile
# Dockerfile.test
FROM python:3.9-slim

WORKDIR /app

COPY requirements-integration.txt .
RUN pip install -r requirements-integration.txt

COPY . .

CMD ["pytest", "tests/integration/", "-v"]
```

### æµ‹è¯•æ‰§è¡Œå‘½ä»¤
```bash
# æ‰§è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•
pytest tests/integration/ -v

# æ‰§è¡Œç‰¹å®šæ ‡è®°çš„æµ‹è¯•
pytest -m "integration and not slow" tests/integration/

# æ‰§è¡Œå¤–éƒ¨ä¾èµ–æµ‹è¯•ï¼ˆéœ€è¦æœåŠ¡å¯åŠ¨ï¼‰
pytest -m "external" tests/integration/

# å¹¶è¡Œæ‰§è¡Œæµ‹è¯•
pytest -n 4 tests/integration/
```

## ğŸ“ˆ æŒç»­é›†æˆé…ç½®

### GitHub Actionsé…ç½®
```yaml
# .github/workflows/integration-tests.yml
name: Integration Tests

on: [push, pull_request]

jobs:
  integration-tests:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r requirements-integration.txt
    
    - name: Run integration tests
      run: |
        pytest tests/integration/ -v --tb=short
      env:
        DATABASE_URL: postgresql://postgres:test@localhost/test
```

## ğŸ“ æœ€ä½³å®è·µ

### é›†æˆæµ‹è¯•åŸåˆ™
1. **çœŸå®ç¯å¢ƒ** - å°½å¯èƒ½æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒ
2. **æ•°æ®éš”ç¦»** - æµ‹è¯•æ•°æ®ä¸å½±å“å…¶ä»–æµ‹è¯•
3. **ä¾èµ–ç®¡ç†** - æ˜ç¡®å¤–éƒ¨ä¾èµ–çš„å¤„ç†æ–¹å¼
4. **é”™è¯¯æ¨¡æ‹Ÿ** - æµ‹è¯•å„ç§å¼‚å¸¸æƒ…å†µ

### å¸¸è§é™·é˜±
- âŒ **æµ‹è¯•é—´ä¾èµ–** - æµ‹è¯•é¡ºåºä¸åº”å½±å“ç»“æœ
- âŒ **ç¡¬ç¼–ç é…ç½®** - ä½¿ç”¨ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶
- âŒ **å¿½ç•¥æ¸…ç†** - æµ‹è¯•åå¿…é¡»æ¸…ç†èµ„æº
- âŒ **è¿‡åº¦é›†æˆ** - é¿å…æµ‹è¯•èŒƒå›´è¿‡å¤§

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜
1. **è¿æ¥è¶…æ—¶** - æ£€æŸ¥ç½‘ç»œå’ŒæœåŠ¡çŠ¶æ€
2. **æ•°æ®æ±¡æŸ“** - ç¡®ä¿æµ‹è¯•æ•°æ®éš”ç¦»
3. **ç‰ˆæœ¬ä¸å…¼å®¹** - éªŒè¯ä¾èµ–ç‰ˆæœ¬åŒ¹é…
4. **èµ„æºæ³„éœ²** - æ£€æŸ¥è¿æ¥å’Œæ–‡ä»¶å¥æŸ„

### è°ƒè¯•æŠ€å·§
```python
# æ·»åŠ è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# ä½¿ç”¨æ–­ç‚¹è°ƒè¯•
import pdb; pdb.set_trace()

# è¾“å‡ºä¸­é—´çŠ¶æ€
print(f"ä¸­é—´ç»“æœ: {intermediate_result}")
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [æµ‹è¯•æ¦‚è¿°](01-æµ‹è¯•æ¦‚è¿°.md) - æ•´ä½“æµ‹è¯•ç­–ç•¥
- [å•å…ƒæµ‹è¯•æŒ‡å—](02-å•å…ƒæµ‹è¯•.md) - å•å…ƒæµ‹è¯•æ–¹æ³•
- [æ€§èƒ½æµ‹è¯•æŒ‡å—](04-æ€§èƒ½æµ‹è¯•.md) - æ€§èƒ½æµ‹è¯•ç­–ç•¥
- [æµ‹è¯•æ•°æ®ç®¡ç†](05-æµ‹è¯•æ•°æ®ç®¡ç†.md) - æµ‹è¯•æ•°æ®è§„èŒƒ

---

*ğŸ¯ é›†æˆæµ‹è¯•ç¡®ä¿ç³»ç»Ÿå„éƒ¨åˆ†ååŒå·¥ä½œï¼Œæ˜¯ä¿è¯äº§å“è´¨é‡çš„é‡è¦ç¯èŠ‚ã€‚*